---
title: 【模型解释二】
tags: [模型解释]

author: Yude Bai
date: 2021-12-18
img: /medias/featureimages/10.jpg
summary: 模型可解释性 SHAP

toc: true
---


# :whale: 模型可解释性 SHAP :whale:

## 1、SHAP 简介
SHAP 全称 **SH**apley **A**dditive ex**P**lanation，发表于 [NIPS 2017](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) 。

![SHAP](https://img-blog.csdnimg.cn/eba17c54584542969b13951884bb1828.png#pic_center)

SHAP 属于模型事后解释的方法。核心思想是计算特征对模型输出的边际贡献，再从全局和局部两个层面对**黑盒模型**进行解释。

SHAP 示意图如下所示。

![SHAP 示意图](https://img-blog.csdnimg.cn/2a54fb59929246a8a4be97dcb128ee30.png#pic_center)


## 2、SHAP 环境配置

本地环境为 WIndows 10 + python 3.6.2。根据 [SHAP source code](https://github.com/slundberg/shap) 直接 ```pip install shap``` 即可。


## 3、SHAP 测试

以 [SHAP source code](https://github.com/slundberg/shap) 中的 Boston 房价为例，SHAP 可以提供：
 - 任一样本的各个特征对其类别 (分类概率值) 的贡献大小。
 - 单个/多个特征的值的大小对模型预测结果的影响。
 - 参考 [SHAP 的理解与应用](https://zhuanlan.zhihu.com/p/103370775) 可以使 SHAP 适用于 one-hot 编码。

![特征对样本的影响](https://img-blog.csdnimg.cn/0a51899bc7574cfb85fdf2bf72fce137.png#pic_center)

![特征对模型的影响](https://img-blog.csdnimg.cn/9b2bdd08072944369b4ccb1c25cec094.png#pic_center)


## 4、SHAP 相关参考

一些参考如下：
 - [SHAP in kaggle](https://yyqing.me/post/2018/2018-09-25-kaggle-model-insights) 。
 - Github，[SHAP source code](https://github.com/slundberg/shap) 。
 - 中文博客，[SHAP 模型：可解释机器学习模型](https://blog.csdn.net/weixin_41968505/article/details/119885046) ，[SHAP 的理解与应用](https://zhuanlan.zhihu.com/p/103370775) ，[利用 SHAP 解释 Xgboost 模型](https://zhuanlan.zhihu.com/p/64799119) 。
 - 图书，[Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) ，[可解释机器学习 (译)](http://www.broadview.com.cn/book/6530) 。
 - Paper，Lundberg, S. M., & Lee, S. I. (2017, December). A unified approach to interpreting model predictions. In Proceedings of the 31st international conference on neural information processing systems (pp. 4768-4777).



![](https://img-blog.csdnimg.cn/2d2096ac60c0472796d8c602726790f7.png#pic_center)

